{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./', train=True, download=True,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                       (0.1307,),(0.3081,)\n",
    "                                   )\n",
    "                               ])),\n",
    "batch_size = batch_size_train, shuffle=True)\n",
    "\n",
    "#BCELoss: 1/N sum_1^N(y log (y^) + (1-y)*log(1-y^))\n",
    "#SGD: Stochastic Gradient Descent better than Gradient Descent\n",
    "# SGD < Mini-batch Gradient Descent < GD\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./', train=False, download=True,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize(\n",
    "                                       (0.1307,), (0.3081,)\n",
    "                                   )\n",
    "                               ])),\n",
    "batch_size = batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bi, (xi, yi) in enumerate(train_loader):\n",
    "    torchvision.utils.save_image(xi, 'image.png')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 784 = 28 * 28\n",
    "# 512 = 2 ^ 9\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(in_features=784 , out_features= 512),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(512, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "# nn.Sequential = 1 cai thung chua tuan tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossf = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 100\n",
      "0 200\n",
      "0 300\n",
      "0 400\n",
      "0 500\n",
      "0 600\n",
      "0 700\n",
      "0 800\n",
      "0 900\n",
      "Test accuracy at epoch 0 is 0.0980\n",
      "1 0\n",
      "1 100\n",
      "1 200\n",
      "1 300\n",
      "1 400\n",
      "1 500\n",
      "1 600\n",
      "1 700\n",
      "1 800\n",
      "1 900\n",
      "Test accuracy at epoch 1 is 0.0980\n",
      "2 0\n",
      "2 100\n",
      "2 200\n",
      "2 300\n",
      "2 400\n",
      "2 500\n",
      "2 600\n",
      "2 700\n",
      "2 800\n",
      "2 900\n",
      "Test accuracy at epoch 2 is 0.0980\n",
      "3 0\n",
      "3 100\n",
      "3 200\n",
      "3 300\n",
      "3 400\n",
      "3 500\n",
      "3 600\n",
      "3 700\n",
      "3 800\n",
      "3 900\n",
      "Test accuracy at epoch 3 is 0.0980\n",
      "4 0\n",
      "4 100\n",
      "4 200\n",
      "4 300\n",
      "4 400\n",
      "4 500\n",
      "4 600\n",
      "4 700\n",
      "4 800\n",
      "4 900\n",
      "Test accuracy at epoch 4 is 0.0980\n",
      "5 0\n",
      "5 100\n",
      "5 200\n",
      "5 300\n",
      "5 400\n",
      "5 500\n",
      "5 600\n",
      "5 700\n",
      "5 800\n",
      "5 900\n",
      "Test accuracy at epoch 5 is 0.0980\n",
      "6 0\n",
      "6 100\n",
      "6 200\n",
      "6 300\n",
      "6 400\n",
      "6 500\n",
      "6 600\n",
      "6 700\n",
      "6 800\n",
      "6 900\n",
      "Test accuracy at epoch 6 is 0.0980\n",
      "7 0\n",
      "7 100\n",
      "7 200\n",
      "7 300\n",
      "7 400\n",
      "7 500\n",
      "7 600\n",
      "7 700\n",
      "7 800\n",
      "7 900\n",
      "Test accuracy at epoch 7 is 0.0980\n",
      "8 0\n",
      "8 100\n",
      "8 200\n",
      "8 300\n",
      "8 400\n",
      "8 500\n",
      "8 600\n",
      "8 700\n",
      "8 800\n",
      "8 900\n",
      "Test accuracy at epoch 8 is 0.0980\n",
      "9 0\n",
      "9 100\n",
      "9 200\n",
      "9 300\n",
      "9 400\n",
      "9 500\n",
      "9 600\n",
      "9 700\n",
      "9 800\n",
      "9 900\n",
      "Test accuracy at epoch 9 is 0.0980\n",
      "10 0\n",
      "10 100\n",
      "10 200\n",
      "10 300\n",
      "10 400\n",
      "10 500\n",
      "10 600\n",
      "10 700\n",
      "10 800\n",
      "10 900\n",
      "Test accuracy at epoch 10 is 0.0980\n",
      "11 0\n",
      "11 100\n",
      "11 200\n",
      "11 300\n",
      "11 400\n",
      "11 500\n",
      "11 600\n",
      "11 700\n",
      "11 800\n",
      "11 900\n",
      "Test accuracy at epoch 11 is 0.0980\n",
      "12 0\n",
      "12 100\n",
      "12 200\n",
      "12 300\n",
      "12 400\n",
      "12 500\n",
      "12 600\n",
      "12 700\n",
      "12 800\n",
      "12 900\n",
      "Test accuracy at epoch 12 is 0.0980\n",
      "13 0\n",
      "13 100\n",
      "13 200\n",
      "13 300\n",
      "13 400\n",
      "13 500\n",
      "13 600\n",
      "13 700\n",
      "13 800\n",
      "13 900\n",
      "Test accuracy at epoch 13 is 0.0980\n",
      "14 0\n",
      "14 100\n",
      "14 200\n",
      "14 300\n",
      "14 400\n",
      "14 500\n",
      "14 600\n",
      "14 700\n",
      "14 800\n",
      "14 900\n",
      "Test accuracy at epoch 14 is 0.0980\n",
      "15 0\n",
      "15 100\n",
      "15 200\n",
      "15 300\n",
      "15 400\n",
      "15 500\n",
      "15 600\n",
      "15 700\n",
      "15 800\n",
      "15 900\n",
      "Test accuracy at epoch 15 is 0.0980\n",
      "16 0\n",
      "16 100\n",
      "16 200\n",
      "16 300\n",
      "16 400\n",
      "16 500\n",
      "16 600\n",
      "16 700\n",
      "16 800\n",
      "16 900\n",
      "Test accuracy at epoch 16 is 0.0980\n",
      "17 0\n",
      "17 100\n",
      "17 200\n",
      "17 300\n",
      "17 400\n",
      "17 500\n",
      "17 600\n",
      "17 700\n",
      "17 800\n",
      "17 900\n",
      "Test accuracy at epoch 17 is 0.0980\n",
      "18 0\n",
      "18 100\n",
      "18 200\n",
      "18 300\n",
      "18 400\n",
      "18 500\n",
      "18 600\n",
      "18 700\n",
      "18 800\n",
      "18 900\n",
      "Test accuracy at epoch 18 is 0.0980\n",
      "19 0\n",
      "19 100\n",
      "19 200\n",
      "19 300\n",
      "19 400\n",
      "19 500\n",
      "19 600\n",
      "19 700\n",
      "19 800\n",
      "19 900\n",
      "Test accuracy at epoch 19 is 0.0980\n"
     ]
    }
   ],
   "source": [
    "for ei in range(n_epochs):\n",
    "    for bi, (xi, yi) in enumerate(train_loader):\n",
    "        if bi % 100 == 0:\n",
    "            print(ei, bi)\n",
    "        optimizer.zero_grad()\n",
    "        # zero_grad se xoa gradient o step trc\n",
    "        xi = xi.reshape(xi.size(0), -1)\n",
    "        yi_hat = net(xi)\n",
    "        loss_i = lossf(yi_hat, yi)\n",
    "        loss_i.backward()\n",
    "        optimizer.step()    #theta^t = theta^(t-1) - eta * gradient at theta^(t-1)\n",
    "    \n",
    "    test_accuracy = 0\n",
    "    for bi, (xi, yi) in enumerate(test_loader):\n",
    "        xi = xi.reshape(xi.size(0), -1)\n",
    "        yi_hat = net(xi)\n",
    "        yi_predict = yi_hat.argmax(dim = 1)\n",
    "        correct = (yi_predict == yi).sum()\n",
    "        test_accuracy += correct\n",
    "    print('Test accuracy at epoch %d is %.4f' %(ei, test_accuracy/10000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
